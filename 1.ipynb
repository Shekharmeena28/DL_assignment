{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35e90e4",
   "metadata": {},
   "source": [
    "1. What is the function of a summation junction of a neuron? What is threshold activation\n",
    "function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133c3cb",
   "metadata": {},
   "source": [
    "**Answer**-In a biological neuron or an artificial neuron (as used in artificial neural networks), the summation junction serves as a mathematical operation that aggregates the inputs to the neuron. It's an essential part of the neuron's computation.\n",
    "Summation = (Input_1 * Weight_1) + (Input_2 * Weight_2) + ... + (Input_n * Weight_n)\n",
    "\n",
    "Threshold Activation Function: The result of the summation is then passed through an activation function, often referred to as the activation function or threshold activation function.\n",
    "\n",
    "The activation function introduces non-linearity into the neuron's output. It determines whether the neuron should \"fire\" or become active based on the computed sum.\n",
    "\n",
    "The threshold activation function typically compares the weighted sum (output of the summation junction) to a predefined threshold. If the sum exceeds the threshold, the neuron \"fires\" or produces an output; otherwise, it remains inactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40904e14",
   "metadata": {},
   "source": [
    "2. What is a step function? What is the difference of step function with threshold function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150f4cd",
   "metadata": {},
   "source": [
    "**Answer**-A step function, also known as a Heaviside step function or simply a step function, is a mathematical function that maps an input to a discrete output. It's often used in mathematics and engineering to represent a binary or on/off decision.\n",
    "\n",
    "- Step(x) = 1 if x >= threshold\n",
    "- Step(x) = 0 if x < threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22069bd9",
   "metadata": {},
   "source": [
    "3. Explain the McCulloch–Pitts model of neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fa8a8",
   "metadata": {},
   "source": [
    "**Answer**- The McCulloch-Pitts (M-P) neuron model is one of the earliest conceptual models of an artificial neuron, proposed by Warren McCulloch and Walter Pitts in 1943. This model was foundational in the development of artificial neural networks and laid the groundwork for modern neuron and neural network models.\n",
    "\n",
    "The McCulloch-Pitts neuron model consists of the following components:\n",
    "\n",
    "- Inputs (Dendrites): The neuron receives multiple binary inputs (0 or 1), represented as signals from other neurons or external sources. Each input is either \"on\" (1) or \"off\" (0).\n",
    "\n",
    "- Weights (Synaptic Weights): Each input is associated with a weight, which represents the importance or influence of that input on the neuron's output. These weights can be either positive or negative.\n",
    "\n",
    "- Summation Function: The neuron calculates the weighted sum of its inputs. This is done by multiplying each input by its corresponding weight and then summing up these products.\n",
    "\n",
    "**Summation = (Input_1 * Weight_1) + (Input_2 * Weight_2) + ... + (Input_n * Weight_n)**\n",
    "\n",
    "- Threshold Activation Function: After calculating the weighted sum, the neuron applies a threshold activation function to determine its output. If the calculated sum exceeds a predefined threshold value, the neuron fires (outputs a 1); otherwise, it remains inactive (outputs a 0).\n",
    "\n",
    "- **Output = 1 if Summation >= Threshold**\n",
    "- **Output = 0 if Summation < Threshold**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac841f9",
   "metadata": {},
   "source": [
    "4. Explain the ADALINE network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274086b5",
   "metadata": {},
   "source": [
    "**Answer**-ADALINE, which stands for Adaptive Linear Neuron, is a type of artificial neural network model that was developed as an improvement upon the earlier McCulloch-Pitts neuron model. ADALINE was introduced by Bernard Widrow and Ted Hoff in the late 1950s. It's designed to perform linear regression and pattern recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10efb2dc",
   "metadata": {},
   "source": [
    "5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834c2e6",
   "metadata": {},
   "source": [
    "A simple perceptron is a type of artificial neural network model that has some limitations, particularly when it comes to handling complex real-world datasets. The main constraint and reasons for its potential failure with real-world datasets include:\n",
    "\n",
    "**Constraint of a Simple Perceptron:**\n",
    "\n",
    "Linearity: A simple perceptron can only model linearly separable functions. This means it can learn and represent decision boundaries that are straight lines (in 2D) or hyperplanes (in higher dimensions). In cases where the data is not linearly separable, meaning the decision boundary is curved or non-linear, a simple perceptron will struggle to fit the data accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922e754",
   "metadata": {},
   "source": [
    "6. What is linearly inseparable problem? What is the role of the hidden layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3f133",
   "metadata": {},
   "source": [
    "**Answer**- Linearly inseparable refers to a type of problem or dataset where data points from different classes cannot be separated by a single straight line or hyperplane in the feature space. In other words, there is no linear function that can accurately classify all data points correctly.\n",
    "\n",
    "The role of the hidden layer in a neural network, particularly in a multi-layer perceptron (MLP), is crucial when dealing with linearly inseparable problems. The hidden layer enables the network to learn non-linear relationships and complex patterns within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34664f8b",
   "metadata": {},
   "source": [
    "7. Explain XOR problem in case of a simple perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd6af3",
   "metadata": {},
   "source": [
    "**Answer**- the XOR problem highlights the limitation of a simple perceptron when faced with data that requires non-linear decision boundaries. To handle such problems, multi-layer neural networks with hidden layers and non-linear activation functions are needed to learn and represent complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28548499",
   "metadata": {},
   "source": [
    "8. Design a multi-layer perceptron to implement A XOR B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd53cfd",
   "metadata": {},
   "source": [
    "Designing a multi-layer perceptron (MLP) to implement the XOR function (A XOR B) involves creating a neural network architecture with appropriate layers, neurons, and activation functions. Here's a simple example of an MLP for XOR:\n",
    "\n",
    "Architecture:\n",
    "\n",
    "Input Layer: 2 neurons (for A and B)\n",
    "Hidden Layer: 2 neurons (introducing non-linearity)\n",
    "Output Layer: 1 neuron (for the XOR result)\n",
    "Activation Functions:\n",
    "\n",
    "Sigmoid activation function for the hidden layer.\n",
    "Sigmoid activation function for the output layer.\n",
    "Network Design:\n",
    "\n",
    "Input Layer: This layer has two neurons, one for input A and one for input B.\n",
    "\n",
    "Hidden Layer: The hidden layer has two neurons and uses a sigmoid activation function. Each neuron computes a weighted sum of the inputs from the input layer and passes the result through the sigmoid function.\n",
    "\n",
    "Output Layer: The output layer has one neuron with a sigmoid activation function. It computes a weighted sum of the outputs from the hidden layer and passes the result through the sigmoid function. The output of this neuron represents the XOR result.\n",
    "\n",
    "Weights and Biases:\n",
    "\n",
    "Weights and biases need to be initialized with appropriate values. You can start with random initialization or initialize them to small values.\n",
    "Training:\n",
    "\n",
    "To train this network, you'll need a dataset that includes input pairs (A, B) and their corresponding XOR outputs (A XOR B).\n",
    "Use a training algorithm such as backpropagation with gradient descent to adjust the weights and biases during training.\n",
    "The network should learn to approximate the XOR function by minimizing the difference between its predicted outputs and the actual XOR outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098685a2",
   "metadata": {},
   "source": [
    "9. Explain the single-layer feed forward architecture of ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec25925",
   "metadata": {},
   "source": [
    "**Answer** -\n",
    "\n",
    "\n",
    "A **single-layer feedforward architecture** is one of the simplest forms of an artificial neural network (ANN). It consists of just two layers: an input layer and an output layer. This architecture is also known as a **single-layer perceptron** or **single-layer neural network**. Here's a breakdown of its components and how it works:\n",
    "\n",
    "**Components of a Single-Layer Feedforward ANN:**\n",
    "\n",
    "1. **Input Layer:** This layer consists of input neurons, each representing a feature or input variable. The number of input neurons is determined by the dimensionality of the input data.\n",
    "\n",
    "2. **Output Layer:** The output layer contains neurons responsible for producing the network's output. The number of output neurons depends on the nature of the task:\n",
    "   - For binary classification tasks, there is usually one output neuron.\n",
    "   - For multi-class classification tasks, there is one output neuron for each class.\n",
    "   - For regression tasks, there is one output neuron to predict the continuous target variable.\n",
    "\n",
    "**Working of a Single-Layer Feedforward ANN:**\n",
    "\n",
    "1. **Input:** The input layer receives input data, which is typically a feature vector representing a single data point. Each input neuron in the input layer corresponds to one feature.\n",
    "\n",
    "2. **Weights:** Each connection between an input neuron and an output neuron has an associated weight. These weights represent the importance or influence of each input feature on the network's output. The weights are learned during training.\n",
    "\n",
    "3. **Weighted Sum:** For each output neuron, the network computes a weighted sum of the inputs. This is done by multiplying each input value by its corresponding weight and summing up these products:\n",
    "\n",
    "   ```\n",
    "   Weighted Sum = (Input_1 * Weight_1) + (Input_2 * Weight_2) + ... + (Input_n * Weight_n)\n",
    "   ```\n",
    "\n",
    "4. **Activation Function:** The weighted sum is then passed through an activation function. The choice of activation function depends on the nature of the problem:\n",
    "   - For binary classification, a threshold function (e.g., step function) can be used to produce binary outputs.\n",
    "   - For multi-class classification, a softmax function is often used to produce class probabilities.\n",
    "   - For regression, the identity function (output equals weighted sum) can be used to predict continuous values.\n",
    "\n",
    "5. **Output:** The output of the activation function is the final prediction or output of the network. In binary classification, it might represent a class label (0 or 1). In multi-class classification, it represents class probabilities. In regression, it's the predicted value.\n",
    "\n",
    "**Limitations of a Single-Layer Feedforward ANN:**\n",
    "\n",
    "A single-layer feedforward ANN has some notable limitations:\n",
    "- It can only model linear relationships between inputs and outputs due to its linear activation function.\n",
    "- It cannot capture complex patterns or non-linearities in data.\n",
    "- It is primarily suitable for simple tasks like linear regression or linear binary classification.\n",
    "\n",
    "To handle more complex problems with non-linear patterns, multi-layer neural network architectures, such as multi-layer perceptrons (MLPs), are used. MLPs contain one or more hidden layers with non-linear activation functions, allowing them to learn and represent non-linear relationships in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26ff70",
   "metadata": {},
   "source": [
    "10. Explain the competitive network architecture of ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56af5d",
   "metadata": {},
   "source": [
    "**Answer**-\n",
    "\n",
    "A **competitive network**, also known as a **competitive learning network** or **winner-takes-all network**, is a type of artificial neural network (ANN) architecture that is designed for unsupervised learning and competitive learning scenarios. This network is characterized by its ability to perform competitive learning among a group of neurons. Here's an explanation of the competitive network architecture:\n",
    "\n",
    "**Components of a Competitive Network:**\n",
    "\n",
    "1. **Neurons (Nodes):** A competitive network typically consists of a set of neurons, each representing a cluster or category. These neurons compete with each other to respond to input patterns. The number of neurons in the network is determined by the number of categories or clusters you want the network to learn.\n",
    "\n",
    "2. **Weights:** Each neuron is associated with a weight vector of the same dimension as the input data. These weight vectors determine the responsiveness of each neuron to specific input patterns. During training, these weights are adjusted to learn and represent the categories or clusters in the data.\n",
    "\n",
    "**Working of a Competitive Network:**\n",
    "\n",
    "The operation of a competitive network can be summarized as follows:\n",
    "\n",
    "1. **Initialization:** Initially, the weights of the neurons are typically initialized randomly.\n",
    "\n",
    "2. **Competition:** When an input pattern is presented to the network, each neuron computes its similarity to the input pattern. The similarity is often measured using a similarity metric like Euclidean distance or cosine similarity. Neurons compete to be the one with the highest similarity to the input.\n",
    "\n",
    "3. **Winner-Takes-All (WTA):** The neuron with the highest similarity (i.e., the one that is most responsive to the input pattern) is declared the winner and is said to have \"fired.\" This neuron's weight vector is adjusted to become more similar to the input pattern, thus refining its representation of the category.\n",
    "\n",
    "4. **Learning Rule:** The learning rule used in competitive networks typically involves adjusting the weights of the winning neuron to move them closer to the input pattern. This process encourages the neuron to specialize in recognizing patterns similar to the input.\n",
    "\n",
    "5. **Inhibition:** In many competitive networks, there is a mechanism for inhibiting the other neurons. This inhibition ensures that only one neuron wins in response to an input, leading to a winner-takes-all scenario.\n",
    "\n",
    "6. **Adaptation:** Over time, as the network is exposed to various input patterns, the neurons become specialized in recognizing different categories or clusters in the data. The network's weights stabilize, and each neuron becomes responsible for responding to a specific type of input pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c8cf0",
   "metadata": {},
   "source": [
    "11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the\n",
    "backpropagation algorithm used to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e195e",
   "metadata": {},
   "source": [
    "Backpropagation is a supervised learning algorithm used to train multi-layer feedforward neural networks (also known as multi-layer perceptrons, MLPs). It is a crucial algorithm for updating the network's weights to minimize the difference between predicted and actual outputs during training. Here are the steps of the backpropagation algorithm, along with explanations for each step:\n",
    "\n",
    "**Step 1: Forward Pass**\n",
    "\n",
    "- **Input:** Provide the neural network with a training example, consisting of input data.\n",
    "  \n",
    "- **Forward Propagation:** Perform a forward pass through the network to compute the predicted output. This involves the following sub-steps:\n",
    "  \n",
    "  - Calculate the weighted sum of inputs and bias for each neuron in each layer, starting from the input layer and progressing through the hidden layers to the output layer.\n",
    "  \n",
    "  - Apply the activation function to each neuron's weighted sum to obtain the neuron's output.\n",
    "  \n",
    "  - Pass the output of one layer as the input to the next layer until the final output is computed.\n",
    "\n",
    "**Step 2: Compute Error**\n",
    "\n",
    "- **Target Output:** Compare the predicted output obtained in the forward pass with the actual target output (ground truth) for the given training example.\n",
    "\n",
    "- **Compute Error:** Calculate the error or loss between the predicted output and the target output. The choice of the error function depends on the type of problem, such as mean squared error (MSE) for regression or cross-entropy for classification.\n",
    "\n",
    "**Step 3: Backward Pass (Backpropagation)**\n",
    "\n",
    "- **Error Gradient:** Compute the gradient of the error with respect to the network's weights and biases. This gradient represents the direction and magnitude of weight adjustments needed to minimize the error.\n",
    "\n",
    "- **Backward Propagation:** Perform a backward pass through the network to calculate the gradients of the error for each weight and bias. This involves the following sub-steps:\n",
    "\n",
    "  - Starting from the output layer, calculate the gradient of the error with respect to the output of each neuron in the output layer using the chain rule.\n",
    "\n",
    "  - Propagate these gradients backward through the network, calculating the gradients for the hidden layers. Each layer's gradients depend on the gradients of the following layer.\n",
    "\n",
    "  - Keep track of the gradients with respect to each weight and bias in the network.\n",
    "\n",
    "**Step 4: Update Weights and Biases**\n",
    "\n",
    "- **Learning Rate:** Choose a learning rate, a small positive scalar that controls the size of weight and bias updates in each iteration. A too-small learning rate can slow down convergence, while a too-large learning rate can cause overshooting.\n",
    "\n",
    "- **Weight and Bias Updates:** Use the gradients calculated in the backward pass to update the weights and biases of the network. This step involves the following sub-steps:\n",
    "\n",
    "  - Multiply the gradient by the learning rate to determine the step size for the weight and bias updates.\n",
    "\n",
    "  - Subtract the scaled gradient from each weight and bias in the network for all layers, including the input layer, to minimize the error.\n",
    "\n",
    "  - Repeat these weight and bias updates for multiple iterations (epochs) and for a batch of training examples if using mini-batch gradient descent.\n",
    "\n",
    "**Step 5: Repeat**\n",
    "\n",
    "- **Training Loop:** Repeat steps 1 to 4 for a specified number of iterations (epochs) or until the error converges to a satisfactory level.\n",
    "\n",
    "- **Epochs:** An epoch is a complete pass through the entire training dataset.\n",
    "\n",
    "The backpropagation algorithm iteratively updates the network's weights and biases to minimize the error between predicted and actual outputs, effectively training the network to make accurate predictions. The process continues until the error converges to a stable and low value, indicating that the network has learned the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecee98",
   "metadata": {},
   "source": [
    "12. What are the advantages and disadvantages of neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce11125",
   "metadata": {},
   "source": [
    "**Advantages of Neural Networks:**\n",
    "\n",
    "1. **Non-Linearity:** Neural networks can model complex and non-linear relationships in data, making them suitable for a wide range of tasks where linear models fall short.\n",
    "\n",
    "2. **Universal Approximators:** Multi-layer neural networks with hidden layers have the capability to approximate any continuous function, given a sufficient number of neurons, making them highly versatile.\n",
    "\n",
    "3. **Feature Learning:** Deep neural networks can automatically learn relevant features from raw data, reducing the need for manual feature engineering.\n",
    "\n",
    "4. **Parallel Processing:** Neural networks can be efficiently parallelized, allowing for faster training and inference on modern hardware like GPUs and TPUs.\n",
    "\n",
    "5. **Scalability:** Neural networks can scale with increasing data and computational resources, making them suitable for large datasets and complex problems.\n",
    "\n",
    "6. **Adaptability:** They can adapt to changing data distributions and new tasks by fine-tuning or retraining, reducing the need for frequent model redesign.\n",
    "\n",
    "7. **State-of-the-Art Performance:** In various domains such as computer vision, natural language processing, and speech recognition, deep neural networks have achieved state-of-the-art performance.\n",
    "\n",
    "**Disadvantages of Neural Networks:**\n",
    "\n",
    "1. **Complexity:** Neural networks can be difficult to design and tune due to their architecture's complexity, and they often require a large amount of data for training.\n",
    "\n",
    "2. **Overfitting:** They are prone to overfitting, especially when the model is too complex or when there is limited training data.\n",
    "\n",
    "3. **Computationally Intensive:** Training deep neural networks can be computationally intensive and time-consuming, requiring access to powerful hardware.\n",
    "\n",
    "4. **Data Hungry:** Deep neural networks require a substantial amount of labeled training data, which may not always be available, especially for niche tasks.\n",
    "\n",
    "5. **Black Box:** The inner workings of deep neural networks are often seen as a \"black box,\" making it challenging to interpret and explain their decisions.\n",
    "\n",
    "6. **Hyperparameter Sensitivity:** Neural networks have many hyperparameters (e.g., learning rate, architecture, batch size) that require careful tuning, which can be labor-intensive.\n",
    "\n",
    "7. **Local Minima:** During training, neural networks may get stuck in local minima, affecting convergence and final performance.\n",
    "\n",
    "8. **Lack of Causality:** Neural networks excel at pattern recognition but may not capture causal relationships in data, which can be important in some applications.\n",
    "\n",
    "In summary, neural networks offer tremendous flexibility and capabilities but come with challenges related to complexity, data requirements, overfitting, and interpretability. Their suitability depends on the specific problem and the availability of resources and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e1eb39",
   "metadata": {},
   "source": [
    "13. Write short notes on any two of the following:\n",
    "\n",
    "- 1. Biological neuron\n",
    "- 2. ReLU function\n",
    "- 3. Single-layer feed forward ANN\n",
    "- 4. Gradient descent\n",
    "- 5. Recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0cb825",
   "metadata": {},
   "source": [
    "**Biological Neuron:**\n",
    "\n",
    "A biological neuron, also known as a nerve cell, is the fundamental unit of the nervous system in living organisms, including humans. These neurons are highly specialized cells designed to transmit information through electrical and chemical signals. Here are key points about biological neurons:\n",
    "\n",
    "- **Structure:** A biological neuron consists of several components, including a cell body (soma), dendrites, an axon, and synapses.\n",
    "\n",
    "- **Dendrites:** Dendrites are branching extensions from the cell body that receive signals (input) from other neurons and transmit them toward the cell body.\n",
    "\n",
    "- **Axon:** The axon is an elongated fiber that extends from the cell body and carries electrical impulses (action potentials) away from the neuron. Axons can be quite long, facilitating communication between distant parts of the nervous system.\n",
    "\n",
    "- **Synapses:** Synapses are the junctions between the axon of one neuron and the dendrites or cell body of another neuron. At synapses, chemical neurotransmitters are released to transmit signals from one neuron to another.\n",
    "\n",
    "- **Action Potential:** An action potential is an electrical signal that travels along the axon when a neuron is sufficiently stimulated. This signal is essential for transmitting information over long distances.\n",
    "\n",
    "- **Function:** Biological neurons play a crucial role in processing sensory information, controlling muscle movements, regulating bodily functions, and supporting cognitive processes in the human brain.\n",
    "\n",
    "Biological neurons form complex networks in the nervous system, allowing organisms to sense their environment, process information, make decisions, and coordinate bodily functions.\n",
    "\n",
    "**ReLU Function (Rectified Linear Unit):**\n",
    "\n",
    "The Rectified Linear Unit (ReLU) function is a widely used activation function in artificial neural networks, particularly in deep learning models. It has gained popularity due to its simplicity and effectiveness. The ReLU function is defined as follows:\n",
    "\n",
    "```\n",
    "ReLU(x) = max(0, x)\n",
    "```\n",
    "\n",
    "- When the input `x` is positive or zero, ReLU outputs the same value (`x`).\n",
    "- When the input `x` is negative, ReLU outputs zero.\n",
    "\n",
    "**Advantages of ReLU:**\n",
    "\n",
    "- **Non-Linearity:** ReLU introduces non-linearity into the network, allowing it to learn complex relationships in the data.\n",
    "\n",
    "- **Efficiency:** Computationally, ReLU is efficient to calculate, making it suitable for deep networks.\n",
    "\n",
    "- **Mitigates Vanishing Gradient Problem:** ReLU helps mitigate the vanishing gradient problem, which can hamper the training of deep networks with activation functions like sigmoid or tanh.\n",
    "\n",
    "However, ReLU also has some drawbacks, including the potential for \"dying\" neurons (neurons that always output zero) during training. Variations like Leaky ReLU and Parametric ReLU (PReLU) have been introduced to address this issue by allowing a small gradient for negative inputs.\n",
    "\n",
    "ReLU has become the default choice for activation functions in many neural network architectures due to its simplicity and effectiveness in training deep networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
